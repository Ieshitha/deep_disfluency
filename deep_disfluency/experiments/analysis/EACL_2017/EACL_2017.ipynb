{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Computes the accuracies for the outputs from the EACL 2017 experiments on\n",
    "#joint incremental utterance segmentation and disfluency detection\n",
    "#this assumes the experiments are in simple_rnn_disf/rnn_disf_detection/experiments/\n",
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "# from mumodo.mumodoIO import open_intervalframe_from_textgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add the evaluation module functions\n",
    "sys.path.append(\"../../../../\")\n",
    "from deep_disfluency.evaluation.disf_evaluation import incremental_output_disfluency_eval_from_file\n",
    "from deep_disfluency.evaluation.disf_evaluation import final_output_disfluency_eval_from_file, ACCURACY_HEADER\n",
    "from deep_disfluency.evaluation.eval_utils import get_tag_data_from_corpus_file\n",
    "from deep_disfluency.evaluation.results_utils import convert_to_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_dir = \"../../../../deep_disfluency\"\n",
    "experiment_dir = top_dir + \"/experiments\"\n",
    "#experiment_dir = \"/home/dsg-labuser/Desktop/rnn_experiments/\"\n",
    "all_results = {}\n",
    "all_error_dicts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 45 RNN\n",
      "heldout\n",
      "loading data ../../../../rnn_disf_detection//data/disfluency_detection/switchboard/swbd_heldout_partial_timings_data.csv\n",
      "loaded 104 sequences\n",
      "104 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julian/.local/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "word\n",
      "interval\n",
      "r_<rm.<i.<rp_interval 0.244318848636\n",
      "pearson_r_p_value_rps_number 2.47371064803e-66\n",
      "p_<rms_interval 0\n",
      "f1_<rm_word 0\n",
      "t_t_detection_<rps_interval 0.238689839572\n",
      "f1_<rpnsub_word 0\n",
      "r_<rpnsub_word 0\n",
      "r_t>_interval 0\n",
      "p_<i_interval 0.409424379233\n",
      "pearson_r_p_value_rps_rate_per_word 6.80692621974e-55\n",
      "f1_<rpnrep_interval 0\n",
      "r_<e_interval 0.914806512382\n",
      "NIST_SU_interval 53.0006978367\n",
      "f1_<rps_relaxed_interval 0.773198482933\n",
      "    p_<rps_relaxed_word None\n",
      "    delayed_acc_<rm_mean_interval None\n",
      "f1_<rpndel_word 0\n",
      "f1_<rpndel_interval 0\n",
      "r_<rpnrep_word 0\n",
      "p_<rm.<i.<rp_word 0.79677877783\n",
      "    delayed_acc_<rm_mean_word None\n",
      "f1_<rpn_interval 0\n",
      "    p_<e_interval None\n",
      "t_t_detection_t>_word 0.335757575758\n",
      "f1_<rp_interval 0.46382101234\n",
      "delayed_acc_<rm_3_word None\n",
      "r_<rm.<i.<rp_word 0.235014670952\n",
      "f1_<rm_interval 0\n",
      "r_<i_word 0.362745098039\n",
      "t_t_detection_<rms_interval nan\n",
      "    f1_<rm_word None\n",
      "p_<rps_interval 0.480109081441\n",
      "delayed_acc_<rm_3_interval None\n",
      "t_t_detection_t>_interval 1.87772097492\n",
      "f1_<rp_word 0.559730790802\n",
      "p_<rpn_interval 0\n",
      "pearson_r_correl_rps_number 0.972458354655\n",
      "DSER_word 62.4040474529\n",
      "r_<rps_relaxed_word 0.718347401155\n",
      "r_<rps_interval 0.653552707669\n",
      "f1_<e_word 0.914533180487\n",
      "r_<rp_interval 0.446633846778\n",
      "r_<e_word 0.89952392884\n",
      "edit_overhead_rel_<rm None\n",
      "    p_<rps_relaxed_interval None\n",
      "t_t_detection_<e_interval 0.610932286555\n",
      "SegER None\n",
      "r_<rm_word 0\n",
      "p_<rms_word 0\n",
      "p_<rpnsub_interval 0\n",
      "f1_<rms_interval 0\n",
      "p_<rps_word 0.814004376368\n",
      "r_<rpn_word 0\n",
      "    processing_overhead_interval None\n",
      "    delayed_acc_<rm_2_interval None\n",
      "p_<rm.<i.<rp_interval 0.473105675498\n",
      "    edit_overhead_rel_tto None\n",
      "r_<rm_interval 0\n",
      "f1_<e_relaxed_interval 0.896879240163\n",
      "p_<rpndel_interval 0\n",
      "f1_<rm.<i.<rp_interval 0.322232179226\n",
      "p_<rp_interval 0.482383895413\n",
      "p_<rpndel_word 0\n",
      "r_<rms_word 0\n",
      "f1_<rm.<rp.<i_interval None\n",
      "    processing_overhead_word None\n",
      "    p_t>_interval None\n",
      "    delayed_acc_<rm_2_word None\n",
      "r_<rps_relaxed_interval 0.693109700816\n",
      "    p_<e_relaxed_word None\n",
      "p_t>_word 0.796486090776\n",
      "t_t_detection_<e_word 0.604260089686\n",
      "    p_<e_relaxed_interval None\n",
      "r_<rps_word 0.661039537983\n",
      "    p_<rm.<rp.<i_word None\n",
      "t_t_detection_<rms_word nan\n",
      "f1_<rpnsub_interval 0\n",
      "    p_<e_word None\n",
      "p_<rpn_word 0\n",
      "f1_t>_interval 0\n",
      "t_t_detection_<rps_word 1.0006684492\n",
      "    t_t_detection_<rms_word None\n",
      "f1_<e_relaxed_word 0\n",
      "\\ r_t>_relaxed_interval None\n",
      "p_<rps_relaxed_word 0.884573304158\n",
      "r_<rpndel_word 0\n",
      "NIST_SU_word 57.6064200977\n",
      "f1_<rms_word 0\n",
      "NIST_SU None\n",
      "r_<rm.<rp.<i_word None\n",
      "p_t>_relaxed_word 0\n",
      "r_<rpn_interval 0\n",
      "r_<rpnsub_interval 0\n",
      "r_<rp_word 0.425163305879\n",
      "r_<rpndel_interval 0\n",
      "    delayed_acc_<rm_4_word None\n",
      "p_t>_relaxed_interval 0.923101067169\n",
      "\\ r_t>_relaxed_word None\n",
      "f1_<rm.<i.<rp_word 0.362969356927\n",
      "delayed_acc_<rm_1_interval None\n",
      "f1_<rps_interval 0.553562964133\n",
      "f1_<rps_relaxed_word 0.792841382692\n",
      "delayed_acc_<rm_6_interval None\n",
      "r_<rm.<rp.<i_interval None\n",
      "f1_<rm.<rp.<i_word None\n",
      "r_<rms_interval 0\n",
      "p_<rm_word 0\n",
      "    p_<rps_interval None\n",
      "    p_<rm.<rp.<i_interval None\n",
      "    f1_<rm_interval None\n",
      "f1_t>_word 0.664089521872\n",
      "p_<rpnrep_interval 0\n",
      "edit_overhead_rel_word 11.1042919684\n",
      "    delayed_acc_<rm_5_word None\n",
      "    t_t_detection_final_t>_interval None\n",
      "f1_<rpn_word 0\n",
      "r_t>_relaxed_interval 0.537758273907\n",
      "    t_t_detection_<rms_interval None\n",
      "r_<rpnrep_interval 0\n",
      "p_<rpnrep_word 0\n",
      "    t_t_detection_<e_interval None\n",
      "edit_overhead_rel_interval 11.1042919684\n",
      "f1_<rpnrep_word 0\n",
      "    p_<rps_word None\n",
      "p_<rps_relaxed_interval 0.874213836478\n",
      "p_<i_word 0.65371024735\n",
      "    delayed_acc_<rm_4_interval None\n",
      "r_<e_relaxed_interval 0.851365275631\n",
      "delayed_acc_<rm_1_word None\n",
      "f1_<rps_word 0.729590585928\n",
      "f1_<i_word 0.46658259773\n",
      "f1_<i_interval 0.392621989718\n",
      "pearson_r_correl_rps_rate_per_utt 0.905868257067\n",
      "DSER None\n",
      "    t_t_detection_<e_word None\n",
      "p_<e_relaxed_interval 0.94753440367\n",
      "    delayed_acc_<rm_5_interval None\n",
      "f1_t>_relaxed_interval 0.679607163489\n",
      "p_<e_interval 0.177639768223\n",
      "DSER_interval 61.6015352408\n",
      "p_<rpnsub_word 0\n",
      "pearson_r_correl_rps_rate_per_word 0.953404229368\n",
      "r_t>_relaxed_word 0\n",
      "p_<e_relaxed_word 0\n",
      "    p_t>_word None\n",
      "p_t>_interval 0\n",
      "f1_<e_interval 0.297508481129\n",
      "p_<e_word 0.930051813472\n",
      "    t_t_detection_final_t>_word None\n",
      "p_<rm_interval 0\n",
      "f1_t>_relaxed_word 0\n",
      "p_<rp_word 0.818927789934\n",
      "r_<i_interval 0.377144342402\n",
      "r_<e_relaxed_word 0\n",
      "r_t>_word 0.569434752268\n",
      "pearson_r_p_value_rps_rate_per_utt 7.65385116377e-40\n",
      "delayed_acc_<rm_6_word None\n",
      "heldout_asr\n",
      "loading data ../../../../rnn_disf_detection//data/disfluency_detection/switchboard/swbd_heldout_partial_timings_data.csv\n",
      "loaded 104 sequences\n",
      "58 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= False interval= True utt_eval= True\n",
      "correcting length of words\n",
      "4617A not in gold\n",
      "4617B not in gold\n",
      "4618A not in gold\n",
      "4618B not in gold\n",
      "4626A not in gold\n",
      "4626B not in gold\n",
      "4649A not in gold\n",
      "4649B not in gold\n",
      "4698A not in gold\n",
      "4698B not in gold\n",
      "4736A not in gold\n",
      "4736B not in gold\n",
      "correcting length of words\n",
      "4801A not in gold\n",
      "4801B not in gold\n",
      "4812A not in gold\n",
      "4812B not in gold\n",
      "correcting length of words\n",
      "correcting length of words\n",
      "correcting length of words\n",
      "correcting length of words\n",
      "correcting length of words\n",
      "correcting length of words\n",
      "correcting length of words\n",
      "correcting length of words\n",
      "correcting length of words\n",
      "correcting length of words\n",
      "correcting length of words\n",
      "4834A not in gold\n",
      "4834B not in gold\n",
      "4858A not in gold\n",
      "4858B not in gold\n",
      "4876A not in gold\n",
      "4876B not in gold\n",
      "4880A not in gold\n",
      "4880B not in gold\n",
      "4902A not in gold\n",
      "4902B not in gold\n",
      "final output disfluency evaluation\n",
      "word= False interval= True utt_eval= True\n",
      "4617A not in gold\n",
      "4617B not in gold\n",
      "4618A not in gold\n",
      "4618B not in gold\n",
      "4626A not in gold\n",
      "4626B not in gold\n",
      "4649A not in gold\n",
      "4649B not in gold\n",
      "4698A not in gold\n",
      "4698B not in gold\n",
      "4736A not in gold\n",
      "4736B not in gold\n",
      "4801A not in gold\n",
      "4801B not in gold\n",
      "4812A not in gold\n",
      "4812B not in gold\n",
      "4834A not in gold\n",
      "4834B not in gold\n",
      "4858A not in gold\n",
      "4858B not in gold\n",
      "4876A not in gold\n",
      "4876B not in gold\n",
      "4880A not in gold\n",
      "4880B not in gold\n",
      "4902A not in gold\n",
      "4902B not in gold\n",
      "interval\n",
      "r_<rm.<i.<rp_interval 0.144823148456\n",
      "r_t>_interval 0\n",
      "f1_<rpnrep_interval 0\n",
      "pearson_r_p_value_rps_rate_per_utt 1.01354674769e-08\n",
      "t_t_detection_<rps_interval 0.218202247191\n",
      "    p_<rps_relaxed_interval None\n",
      "pearson_r_p_value_rps_rate_per_word 2.00814961018e-10\n",
      "r_<e_interval 0.598137957291\n",
      "r_<e_relaxed_interval 0.71189279732\n",
      "p_<i_interval 0.248780487805\n",
      "f1_<rps_relaxed_interval 0.612297734628\n",
      "\\ r_t>_relaxed_interval None\n",
      "    delayed_acc_<rm_mean_interval None\n",
      "r_<rpn_interval 0\n",
      "r_<rpnsub_interval 0\n",
      "f1_<e_interval 0.598998318978\n",
      "f1_<rpndel_interval 0\n",
      "p_t>_relaxed_interval 0.863323500492\n",
      "p_<rp_interval 0.307631357401\n",
      "f1_<rpn_interval 0\n",
      "    p_<e_interval None\n",
      "delayed_acc_<rm_1_interval None\n",
      "f1_<rps_interval 0.327138360476\n",
      "f1_t>_relaxed_interval 0.673571154584\n",
      "f1_<rp_interval 0.284224011713\n",
      "r_<rm.<rp.<i_interval None\n",
      "r_<rms_interval 0\n",
      "f1_<rm_interval 0\n",
      "    p_<rps_interval None\n",
      "    p_<rm.<rp.<i_interval None\n",
      "p_<rpnrep_interval 0\n",
      "    f1_<rm_interval None\n",
      "p_<rps_interval 0.295944139058\n",
      "delayed_acc_<rm_3_interval None\n",
      "t_t_detection_t>_interval 2.90838636364\n",
      "f1_<rms_interval 0\n",
      "pearson_r_correl_rps_number 0.748310262838\n",
      "r_<rps_interval 0.36568351487\n",
      "    t_t_detection_final_t>_interval None\n",
      "r_<rp_interval 0.264126876143\n",
      "p_<e_interval 0.59986115932\n",
      "edit_overhead_rel_<rm None\n",
      "    t_t_detection_<rms_interval None\n",
      "t_t_detection_<e_interval 0.716455026455\n",
      "SegER None\n",
      "r_<rpnrep_interval 0\n",
      "t_t_detection_<rms_interval nan\n",
      "    t_t_detection_<e_interval None\n",
      "edit_overhead_rel_interval 20.0800619835\n",
      "NIST_SU_interval 132.294787298\n",
      "DSER_interval 96.5248651887\n",
      "p_<rpnsub_interval 0\n",
      "p_<rps_relaxed_interval 0.545559400231\n",
      "    delayed_acc_<rm_4_interval None\n",
      "    processing_overhead_interval None\n",
      "    delayed_acc_<rm_2_interval None\n",
      "p_<rm.<i.<rp_interval 0.299853876569\n",
      "f1_<i_interval 0.229695240955\n",
      "    edit_overhead_rel_tto None\n",
      "r_<rm_interval 0\n",
      "f1_<e_relaxed_interval 0.77519379845\n",
      "p_<rpndel_interval 0\n",
      "f1_<rm.<i.<rp_interval 0.195313812217\n",
      "pearson_r_correl_rps_rate_per_utt 0.818904628858\n",
      "DSER None\n",
      "f1_<rm.<rp.<i_interval None\n",
      "p_<e_relaxed_interval 0.850850850851\n",
      "    delayed_acc_<rm_5_interval None\n",
      "r_<rpndel_interval 0\n",
      "p_<rpn_interval 0\n",
      "r_<rps_relaxed_interval 0.697640117994\n",
      "pearson_r_correl_rps_rate_per_word 0.863457772694\n",
      "r_t>_relaxed_interval 0.552201257862\n",
      "NIST_SU None\n",
      "p_t>_interval 0\n",
      "    p_<e_relaxed_interval None\n",
      "p_<rms_interval 0\n",
      "delayed_acc_<rm_6_interval None\n",
      "    p_t>_interval None\n",
      "f1_<rpnsub_interval 0\n",
      "p_<rm_interval 0\n",
      "r_<i_interval 0.21332961517\n",
      "f1_t>_interval 0\n",
      "pearson_r_p_value_rps_number 8.46889065241e-07\n",
      "test\n",
      "loading data ../../../../rnn_disf_detection//data/disfluency_detection/switchboard/swbd_test_partial_timings_data.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "final output disfluency evaluation\n",
      "word= True interval= True utt_eval= True\n",
      "word\n",
      "interval\n",
      "r_<rm.<i.<rp_interval 0.214378002067\n",
      "pearson_r_p_value_rps_number 4.14926044936e-51\n",
      "p_<rms_interval 0\n",
      "f1_<rm_word 0\n",
      "t_t_detection_<rps_interval 0.253189013035\n",
      "f1_<rpnsub_word 0\n",
      "r_<rpnsub_word 0\n",
      "r_t>_interval 0\n",
      "p_<i_interval 0.39897346019\n",
      "pearson_r_p_value_rps_rate_per_word 2.02881566551e-36\n",
      "f1_<rpnrep_interval 0\n",
      "r_<e_interval 0.905886266638\n",
      "NIST_SU_interval 47.102931152\n",
      "f1_<rps_relaxed_interval 0.729630861324\n",
      "    p_<rps_relaxed_word None\n",
      "    delayed_acc_<rm_mean_interval None\n",
      "f1_<rpndel_word 0\n",
      "f1_<rpndel_interval 0\n",
      "r_<rpnrep_word 0\n",
      "p_<rm.<i.<rp_word 0.779497098646\n",
      "    delayed_acc_<rm_mean_word None\n",
      "f1_<rpn_interval 0\n",
      "    p_<e_interval None\n",
      "t_t_detection_t>_word 0.349865229111\n",
      "f1_<rp_interval 0.415549041264\n",
      "delayed_acc_<rm_3_word None\n",
      "r_<rm.<i.<rp_word 0.204464738711\n",
      "f1_<rm_interval 0\n",
      "r_<i_word 0.297180043384\n",
      "t_t_detection_<rms_interval nan\n",
      "    f1_<rm_word None\n",
      "p_<rps_interval 0.436673199412\n",
      "delayed_acc_<rm_3_interval None\n",
      "t_t_detection_t>_interval 1.81438707648\n",
      "f1_<rp_word 0.505660377358\n",
      "p_<rpn_interval 0\n",
      "pearson_r_correl_rps_number 0.949443501856\n",
      "DSER_word 58.0947511929\n",
      "r_<rps_relaxed_word 0.653824362606\n",
      "r_<rps_interval 0.600558323105\n",
      "f1_<e_word 0.908792561192\n",
      "r_<rp_interval 0.39544182959\n",
      "r_<e_word 0.892080536913\n",
      "edit_overhead_rel_<rm None\n",
      "    p_<rps_relaxed_interval None\n",
      "t_t_detection_<e_interval 0.604430386338\n",
      "SegER None\n",
      "r_<rm_word 0\n",
      "p_<rms_word 0\n",
      "p_<rpnsub_interval 0\n",
      "f1_<rms_interval 0\n",
      "p_<rps_word 0.787564766839\n",
      "r_<rpn_word 0\n",
      "    processing_overhead_interval None\n",
      "    delayed_acc_<rm_2_interval None\n",
      "p_<rm.<i.<rp_interval 0.433047776959\n",
      "    edit_overhead_rel_tto None\n",
      "r_<rm_interval 0\n",
      "f1_<e_relaxed_interval 0.885618534169\n",
      "p_<rpndel_interval 0\n",
      "f1_<rm.<i.<rp_interval 0.286784741144\n",
      "p_<rp_interval 0.437810597046\n",
      "p_<rpndel_word 0\n",
      "r_<rms_word 0\n",
      "f1_<rm.<rp.<i_interval None\n",
      "    processing_overhead_word None\n",
      "    p_t>_interval None\n",
      "    delayed_acc_<rm_2_word None\n",
      "r_<rps_relaxed_interval 0.640023337223\n",
      "    p_<e_relaxed_word None\n",
      "p_t>_word 0.80844012373\n",
      "t_t_detection_<e_word 0.571584699454\n",
      "    p_<e_relaxed_interval None\n",
      "r_<rps_word 0.60283286119\n",
      "    p_<rm.<rp.<i_word None\n",
      "t_t_detection_<rms_word nan\n",
      "f1_<rpnsub_interval 0\n",
      "    p_<e_word None\n",
      "p_<rpn_word 0\n",
      "f1_t>_interval 0\n",
      "t_t_detection_<rps_word 1.00652376514\n",
      "    t_t_detection_<rms_word None\n",
      "f1_<e_relaxed_word 0\n",
      "\\ r_t>_relaxed_interval None\n",
      "p_<rps_relaxed_word 0.854182087343\n",
      "r_<rpndel_word 0\n",
      "NIST_SU_word 52.4199045671\n",
      "f1_<rms_word 0\n",
      "NIST_SU None\n",
      "r_<rm.<rp.<i_word None\n",
      "p_t>_relaxed_word 0\n",
      "r_<rpn_interval 0\n",
      "r_<rpnsub_interval 0\n",
      "r_<rp_word 0.371062651436\n",
      "r_<rpndel_interval 0\n",
      "    delayed_acc_<rm_4_word None\n",
      "p_t>_relaxed_interval 0.920955359682\n",
      "\\ r_t>_relaxed_word None\n",
      "f1_<rm.<i.<rp_word 0.323954983923\n",
      "delayed_acc_<rm_1_interval None\n",
      "f1_<rps_interval 0.505668635576\n",
      "f1_<rps_relaxed_word 0.740693196406\n",
      "delayed_acc_<rm_6_interval None\n",
      "r_<rm.<rp.<i_interval None\n",
      "f1_<rm.<rp.<i_word None\n",
      "r_<rms_interval 0\n",
      "p_<rm_word 0\n",
      "    p_<rps_interval None\n",
      "    p_<rm.<rp.<i_interval None\n",
      "    f1_<rm_interval None\n",
      "f1_t>_word 0.704060034635\n",
      "p_<rpnrep_interval 0\n",
      "edit_overhead_rel_word 11.0275421465\n",
      "    delayed_acc_<rm_5_word None\n",
      "    t_t_detection_final_t>_interval None\n",
      "f1_<rpn_word 0\n",
      "r_t>_relaxed_interval 0.577567760342\n",
      "    t_t_detection_<rms_interval None\n",
      "r_<rpnrep_interval 0\n",
      "p_<rpnrep_word 0\n",
      "    t_t_detection_<e_interval None\n",
      "edit_overhead_rel_interval 11.0275421465\n",
      "f1_<rpnrep_word 0\n",
      "    p_<rps_word None\n",
      "p_<rps_relaxed_interval 0.84841453983\n",
      "p_<i_word 0.685\n",
      "    delayed_acc_<rm_4_interval None\n",
      "r_<e_relaxed_interval 0.833973655324\n",
      "delayed_acc_<rm_1_word None\n",
      "f1_<rps_word 0.682926829268\n",
      "f1_<i_word 0.414523449319\n",
      "f1_<i_interval 0.353267195034\n",
      "pearson_r_correl_rps_rate_per_utt 0.858808029051\n",
      "DSER None\n",
      "    t_t_detection_<e_word None\n",
      "p_<e_relaxed_interval 0.944082013048\n",
      "    delayed_acc_<rm_5_interval None\n",
      "f1_t>_relaxed_interval 0.709917808219\n",
      "p_<e_interval 0.175927771495\n",
      "DSER_interval 56.8507157464\n",
      "p_<rpnsub_word 0\n",
      "pearson_r_correl_rps_rate_per_word 0.896480181165\n",
      "r_t>_relaxed_word 0\n",
      "p_<e_relaxed_word 0\n",
      "    p_t>_word None\n",
      "p_t>_interval 0\n",
      "f1_<e_interval 0.294635762709\n",
      "p_<e_word 0.926142697882\n",
      "    t_t_detection_final_t>_word None\n",
      "p_<rm_interval 0\n",
      "f1_t>_relaxed_word 0\n",
      "p_<rp_word 0.79348630644\n",
      "r_<i_interval 0.316956737941\n",
      "r_<e_relaxed_word 0\n",
      "r_t>_word 0.623551465576\n",
      "pearson_r_p_value_rps_rate_per_utt 3.18400216676e-30\n",
      "delayed_acc_<rm_6_word None\n",
      "test_asr\n",
      "loading data ../../../../rnn_disf_detection//data/disfluency_detection/switchboard/swbd_test_partial_timings_data.csv\n",
      "loaded 100 sequences\n",
      "62 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= False interval= True utt_eval= True\n",
      "4013A not in gold\n",
      "4013B not in gold\n",
      "correcting length of words\n",
      "4028A not in gold\n",
      "4028B not in gold\n",
      "4048A not in gold\n",
      "4048B not in gold\n",
      "4055A not in gold\n",
      "4055B not in gold\n",
      "4064A not in gold\n",
      "4064B not in gold\n",
      "4071A not in gold\n",
      "4071B not in gold\n",
      "4074A not in gold\n",
      "4074B not in gold\n",
      "4090A not in gold\n",
      "4090B not in gold\n",
      "4096A not in gold\n",
      "4096B not in gold\n",
      "4103A not in gold\n",
      "4103B not in gold\n",
      "4109A not in gold\n",
      "4109B not in gold\n",
      "4129A not in gold\n",
      "4129B not in gold\n",
      "4130A not in gold\n",
      "4130B not in gold\n",
      "correcting length of words\n",
      "correcting length of words\n",
      "correcting length of words\n",
      "4150A not in gold\n",
      "4150B not in gold\n",
      "correcting length of words\n",
      "correcting length of words\n",
      "final output disfluency evaluation\n",
      "word= False interval= True utt_eval= True\n",
      "4013A not in gold\n",
      "4013B not in gold\n",
      "4028A not in gold\n",
      "4028B not in gold\n",
      "4048A not in gold\n",
      "4048B not in gold\n",
      "4055A not in gold\n",
      "4055B not in gold\n",
      "4064A not in gold\n",
      "4064B not in gold\n",
      "4071A not in gold\n",
      "4071B not in gold\n",
      "4074A not in gold\n",
      "4074B not in gold\n",
      "4090A not in gold\n",
      "4090B not in gold\n",
      "4096A not in gold\n",
      "4096B not in gold\n",
      "4103A not in gold\n",
      "4103B not in gold\n",
      "4109A not in gold\n",
      "4109B not in gold\n",
      "4129A not in gold\n",
      "4129B not in gold\n",
      "4130A not in gold\n",
      "4130B not in gold\n",
      "4150A not in gold\n",
      "4150B not in gold\n",
      "interval\n",
      "r_<rm.<i.<rp_interval 0.111722797927\n",
      "r_t>_interval 0\n",
      "f1_<rpnrep_interval 0\n",
      "pearson_r_p_value_rps_rate_per_utt 6.65933795063e-06\n",
      "t_t_detection_<rps_interval 0.197926829268\n",
      "    p_<rps_relaxed_interval None\n",
      "pearson_r_p_value_rps_rate_per_word 0.000623282689123\n",
      "r_<e_interval 0.520158233064\n",
      "r_<e_relaxed_interval 0.672868217054\n",
      "p_<i_interval 0.274416388757\n",
      "f1_<rps_relaxed_interval 0.542305129913\n",
      "\\ r_t>_relaxed_interval None\n",
      "    delayed_acc_<rm_mean_interval None\n",
      "r_<rpn_interval 0\n",
      "r_<rpnsub_interval 0\n",
      "f1_<e_interval 0.523575671102\n",
      "f1_<rpndel_interval 0\n",
      "p_t>_relaxed_interval 0.832558139535\n",
      "p_<rp_interval 0.230157141427\n",
      "f1_<rpn_interval 0\n",
      "    p_<e_interval None\n",
      "delayed_acc_<rm_1_interval None\n",
      "f1_<rps_interval 0.248692083129\n",
      "f1_t>_relaxed_interval 0.680824088748\n",
      "f1_<rp_interval 0.217889799593\n",
      "r_<rm.<rp.<i_interval None\n",
      "r_<rms_interval 0\n",
      "f1_<rm_interval 0\n",
      "    p_<rps_interval None\n",
      "    p_<rm.<rp.<i_interval None\n",
      "p_<rpnrep_interval 0\n",
      "    f1_<rm_interval None\n",
      "p_<rps_interval 0.215293764388\n",
      "delayed_acc_<rm_3_interval None\n",
      "t_t_detection_t>_interval 3.64900862069\n",
      "f1_<rms_interval 0\n",
      "pearson_r_correl_rps_number 0.488458191633\n",
      "r_<rps_interval 0.294355114608\n",
      "    t_t_detection_final_t>_interval None\n",
      "r_<rp_interval 0.206863979849\n",
      "p_<e_interval 0.527038311233\n",
      "edit_overhead_rel_<rm None\n",
      "    t_t_detection_<rms_interval None\n",
      "t_t_detection_<e_interval 0.744703196347\n",
      "SegER None\n",
      "r_<rpnrep_interval 0\n",
      "t_t_detection_<rms_interval nan\n",
      "    t_t_detection_<e_interval None\n",
      "edit_overhead_rel_interval 20.5270847381\n",
      "NIST_SU_interval 132.686414709\n",
      "DSER_interval 95.7609805924\n",
      "p_<rpnsub_interval 0\n",
      "p_<rps_relaxed_interval 0.465142857143\n",
      "    delayed_acc_<rm_4_interval None\n",
      "    processing_overhead_interval None\n",
      "    delayed_acc_<rm_2_interval None\n",
      "p_<rm.<i.<rp_interval 0.234364385671\n",
      "f1_<i_interval 0.211686879824\n",
      "    edit_overhead_rel_tto None\n",
      "r_<rm_interval 0\n",
      "f1_<e_relaxed_interval 0.718245759206\n",
      "p_<rpndel_interval 0\n",
      "f1_<rm.<i.<rp_interval 0.151313577287\n",
      "pearson_r_correl_rps_rate_per_utt 0.688860238203\n",
      "DSER None\n",
      "f1_<rm.<rp.<i_interval None\n",
      "p_<e_relaxed_interval 0.770186335404\n",
      "    delayed_acc_<rm_5_interval None\n",
      "r_<rpndel_interval 0\n",
      "p_<rpn_interval 0\n",
      "r_<rps_relaxed_interval 0.650159744409\n",
      "pearson_r_correl_rps_rate_per_word 0.55696149754\n",
      "r_t>_relaxed_interval 0.575871313673\n",
      "NIST_SU None\n",
      "p_t>_interval 0\n",
      "    p_<e_relaxed_interval None\n",
      "p_<rms_interval 0\n",
      "delayed_acc_<rm_6_interval None\n",
      "    p_t>_interval None\n",
      "f1_<rpnsub_interval 0\n",
      "p_<rm_interval 0\n",
      "r_<i_interval 0.172300329046\n",
      "f1_t>_interval 0\n",
      "pearson_r_p_value_rps_number 0.00337901854563\n"
     ]
    }
   ],
   "source": [
    "#the evaluation files (as text files)\n",
    "disf_dir = top_dir + \"/data/disfluency_detection/switchboard\"\n",
    "disfluency_files = [\n",
    "                    disf_dir+\"/swbd_heldout_partial_timings_data.csv\",\n",
    "                    disf_dir+\"/swbd_heldout_partial_timings_data.csv\",\n",
    "                    disf_dir+\"/swbd_test_partial_timings_data.csv\",\n",
    "                    disf_dir+\"/swbd_test_partial_timings_data.csv\"\n",
    "                    ]\n",
    "    \n",
    "dialogue_speakers = []\n",
    "good_asr_test = [line.strip(\"\\n\") for line in open(top_dir + \\\n",
    "            \"/data/disfluency_detection/swda_divisions_disfluency_detection/SWDisfTestASRgood_ranges.text\")]\n",
    "good_asr_heldout = [line.strip(\"\\n\") for line in open(top_dir + \\\n",
    "        \"/data/disfluency_detection/swda_divisions_disfluency_detection/SWDisfHeldoutASRgood_ranges.text\")]\n",
    "#Need comparable stopping criterion\n",
    "#1. Weighted F-score all tags  or   loss all tags - have this for all\n",
    "#2. Unweighted F-score all tags would need to recompute for all / per-class loss - would need to recompute for 33\n",
    "#3. Complex rps + tto combined metric as explored - would need to recompute for all, though is closer\n",
    "#allsystemsfinal = [(33,45,'RNN'),(35,6,'LSTM'),\\\n",
    "#                   (36,15,'LSTM (complex tags) (timing)'),\\\n",
    "#                   (34,37,'RNN (complex tags) (timing)')]\n",
    "allsystemsfinal = [\n",
    "    (33,45,'RNN (timing)'),(35,6,'LSTM (timing)'),\n",
    "    (37,6,'LSTM (disf only) (timing)'),\\\n",
    "     (38,8,'LSTM (TTO only) (timing)'),\\\n",
    "              #    (39,2,'LSTM (complex tags)'),\\\n",
    "        ]\n",
    "\n",
    "for exp,e,system in allsystemsfinal:\n",
    "    print exp,e,system\n",
    "    #if 'complex' in system: break\n",
    "    hyp_dir = experiment_dir + \"/0{0}/\".format(exp)\n",
    "    for division, disf_file in zip([\"heldout\", \"heldout_asr\", \"test\", \"test_asr\"],disfluency_files):\n",
    "        #if not division == \"heldout\": continue\n",
    "        print division\n",
    "        IDs, timings, words, pos_tags, labels = get_tag_data_from_corpus_file(disf_file)\n",
    "        #dialogue_speakers.extend(sort_into_dialogue_speakers(IDs,mappings,utts, pos_tags, labels))\n",
    "        if \"heldout\" in division:\n",
    "            good_asr = good_asr_heldout\n",
    "        else:\n",
    "            good_asr = good_asr_test\n",
    "        gold_data = {} #map from the file name to the data\n",
    "        for dialogue,a,b,c,d in zip(IDs, timings, words, pos_tags, labels):\n",
    "            if \"asr\" in division and not dialogue[:4] in good_asr: continue\n",
    "            gold_data[dialogue] = (a,b,c,d)\n",
    "        if \"asr\" in division:\n",
    "            error = False\n",
    "            word = False\n",
    "        else:\n",
    "            error = True\n",
    "            word = True\n",
    "        #the below does just the final output evaluation, assuming a final output file, faster\n",
    "        #results,speaker_rate_dict,error_analysis = final_output_disfluency_eval_from_file(\n",
    "                                    #hyp_dir+\"epoch_{0}/predictions_inc_{1}.final\".format(e,division),\\\n",
    "                                    #gold_data, utt_eval=True, error_analysis=error, word=word, interval=True,\\\n",
    "                                    #outputfilename=None)\n",
    "        #the below does incremental and final output in one, also outputting the final outputs\n",
    "        #derivable from the incremental output, takes quite a while\n",
    "        results,speaker_rate_dict,error_analysis = incremental_output_disfluency_eval_from_file(\n",
    "                                                        hyp_dir+\"epoch_{0}/predictions_inc_{1}.increco\"\n",
    "                                                            .format(e,division),\\\n",
    "                                                        gold_data, \n",
    "                                                        utt_eval=True, \n",
    "                                                        error_analysis=error, \n",
    "                                                        word=word, \n",
    "                                                        interval=True,\\\n",
    "                                                        outputfilename=hyp_dir+\\\n",
    "                                                            \"epoch_{0}/predictions_inc_{1}.final\"\n",
    "                                                            .format(e,division))\n",
    "        for k,v in results.items():\n",
    "            print k,v\n",
    "        all_results[division + \"_\" + system] = deepcopy(results)\n",
    "        all_error_dicts[division + \"_\" + system] = deepcopy(error_analysis)\n",
    "    #break #just one system for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_asr_RNN ************************************\n",
      "pearson_r_p_value_rps_rate_per_word 0.000623282689123\n",
      "pearson_r_correl_rps_rate_per_word 0.55696149754\n",
      "test_RNN ************************************\n",
      "r_<rpnsub_word 0\n",
      "pearson_r_p_value_rps_rate_per_word 2.02881566551e-36\n",
      "    p_<rps_relaxed_word None\n",
      "p_t>_relaxed_word 0\n",
      "r_<rm.<i.<rp_word 0.204464738711\n",
      "    f1_<rm_word None\n",
      "f1_<rp_word 0.505660377358\n",
      "DSER_word 58.0947511929\n",
      "r_<e_word 0.892080536913\n",
      "p_<rps_word 0.787564766839\n",
      "    delayed_acc_<rm_2_word None\n",
      "    p_<e_relaxed_word None\n",
      "edit_overhead_rel_word 11.0275421465\n",
      "r_<rps_word 0.60283286119\n",
      "    p_<e_word None\n",
      "f1_<rpn_word 0\n",
      "p_t>_word 0.80844012373\n",
      "f1_<e_relaxed_word 0\n",
      "p_<rp_word 0.79348630644\n",
      "NIST_SU_word 52.4199045671\n",
      "p_<rps_relaxed_word 0.854182087343\n",
      "r_<rm.<rp.<i_word None\n",
      "r_<rp_word 0.371062651436\n",
      "    delayed_acc_<rm_4_word None\n",
      "p_<i_word 0.685\n",
      "f1_<rm.<i.<rp_word 0.323954983923\n",
      "p_<rm_word 0\n",
      "f1_t>_word 0.704060034635\n",
      "    delayed_acc_<rm_5_word None\n",
      "p_<rpnrep_word 0\n",
      "f1_<rms_word 0\n",
      "f1_<rpnrep_word 0\n",
      "delayed_acc_<rm_1_word None\n",
      "f1_<rps_word 0.682926829268\n",
      "f1_<i_word 0.414523449319\n",
      "    t_t_detection_<e_word None\n",
      "pearson_r_correl_rps_rate_per_word 0.896480181165\n",
      "p_<e_relaxed_word 0\n",
      "    p_t>_word None\n",
      "f1_t>_relaxed_word 0\n",
      "    t_t_detection_<rms_word None\n",
      "    delayed_acc_<rm_mean_word None\n",
      "t_t_detection_t>_word 0.349865229111\n",
      "delayed_acc_<rm_3_word None\n",
      "r_<i_word 0.297180043384\n",
      "f1_<rpndel_word 0\n",
      "r_<rm_word 0\n",
      "p_<rms_word 0\n",
      "r_<rpn_word 0\n",
      "p_<rpndel_word 0\n",
      "r_<rms_word 0\n",
      "f1_<e_word 0.908792561192\n",
      "t_t_detection_<e_word 0.571584699454\n",
      "    p_<rm.<rp.<i_word None\n",
      "t_t_detection_<rms_word nan\n",
      "p_<rpn_word 0\n",
      "t_t_detection_<rps_word 1.00652376514\n",
      "p_<rpnsub_word 0\n",
      "p_<rm.<i.<rp_word 0.779497098646\n",
      "\\ r_t>_relaxed_word None\n",
      "p_<e_word 0.926142697882\n",
      "f1_<rm.<rp.<i_word None\n",
      "f1_<rm_word 0\n",
      "r_<rps_relaxed_word 0.653824362606\n",
      "    processing_overhead_word None\n",
      "    p_<rps_word None\n",
      "r_<rpnrep_word 0\n",
      "f1_<rps_relaxed_word 0.740693196406\n",
      "r_t>_relaxed_word 0\n",
      "    t_t_detection_final_t>_word None\n",
      "r_<rpndel_word 0\n",
      "f1_<rpnsub_word 0\n",
      "r_<e_relaxed_word 0\n",
      "r_t>_word 0.623551465576\n",
      "delayed_acc_<rm_6_word None\n",
      "heldout_asr_RNN ************************************\n",
      "pearson_r_p_value_rps_rate_per_word 2.00814961018e-10\n",
      "pearson_r_correl_rps_rate_per_word 0.863457772694\n",
      "heldout_RNN ************************************\n",
      "r_<rpnsub_word 0\n",
      "pearson_r_p_value_rps_rate_per_word 6.80692621974e-55\n",
      "    p_<rps_relaxed_word None\n",
      "p_t>_relaxed_word 0\n",
      "r_<rm.<i.<rp_word 0.235014670952\n",
      "    f1_<rm_word None\n",
      "f1_<rp_word 0.559730790802\n",
      "DSER_word 62.4040474529\n",
      "r_<e_word 0.89952392884\n",
      "p_<rps_word 0.814004376368\n",
      "    delayed_acc_<rm_2_word None\n",
      "    p_<e_relaxed_word None\n",
      "edit_overhead_rel_word 11.1042919684\n",
      "r_<rps_word 0.661039537983\n",
      "    p_<e_word None\n",
      "f1_<rpn_word 0\n",
      "p_t>_word 0.796486090776\n",
      "f1_<e_relaxed_word 0\n",
      "p_<rp_word 0.818927789934\n",
      "NIST_SU_word 57.6064200977\n",
      "p_<rps_relaxed_word 0.884573304158\n",
      "r_<rm.<rp.<i_word None\n",
      "r_<rp_word 0.425163305879\n",
      "    delayed_acc_<rm_4_word None\n",
      "p_<i_word 0.65371024735\n",
      "f1_<rm.<i.<rp_word 0.362969356927\n",
      "p_<rm_word 0\n",
      "f1_t>_word 0.664089521872\n",
      "    delayed_acc_<rm_5_word None\n",
      "p_<rpnrep_word 0\n",
      "f1_<rms_word 0\n",
      "f1_<rpnrep_word 0\n",
      "delayed_acc_<rm_1_word None\n",
      "f1_<rps_word 0.729590585928\n",
      "f1_<i_word 0.46658259773\n",
      "    t_t_detection_<e_word None\n",
      "pearson_r_correl_rps_rate_per_word 0.953404229368\n",
      "p_<e_relaxed_word 0\n",
      "    p_t>_word None\n",
      "f1_t>_relaxed_word 0\n",
      "    t_t_detection_<rms_word None\n",
      "    delayed_acc_<rm_mean_word None\n",
      "t_t_detection_t>_word 0.335757575758\n",
      "delayed_acc_<rm_3_word None\n",
      "r_<i_word 0.362745098039\n",
      "f1_<rpndel_word 0\n",
      "r_<rm_word 0\n",
      "p_<rms_word 0\n",
      "r_<rpn_word 0\n",
      "p_<rpndel_word 0\n",
      "r_<rms_word 0\n",
      "f1_<e_word 0.914533180487\n",
      "t_t_detection_<e_word 0.604260089686\n",
      "    p_<rm.<rp.<i_word None\n",
      "t_t_detection_<rms_word nan\n",
      "p_<rpn_word 0\n",
      "t_t_detection_<rps_word 1.0006684492\n",
      "p_<rpnsub_word 0\n",
      "p_<rm.<i.<rp_word 0.79677877783\n",
      "\\ r_t>_relaxed_word None\n",
      "p_<e_word 0.930051813472\n",
      "f1_<rm.<rp.<i_word None\n",
      "f1_<rm_word 0\n",
      "r_<rps_relaxed_word 0.718347401155\n",
      "    processing_overhead_word None\n",
      "    p_<rps_word None\n",
      "r_<rpnrep_word 0\n",
      "f1_<rps_relaxed_word 0.792841382692\n",
      "r_t>_relaxed_word 0\n",
      "    t_t_detection_final_t>_word None\n",
      "r_<rpndel_word 0\n",
      "f1_<rpnsub_word 0\n",
      "r_<e_relaxed_word 0\n",
      "r_t>_word 0.569434752268\n",
      "delayed_acc_<rm_6_word None\n"
     ]
    }
   ],
   "source": [
    "#print out the results\n",
    "for div,results in all_results.items():\n",
    "    print div, \"************************************\"\n",
    "    #all_results[div+ \"(complex tags)\"] = results\n",
    "    for r,v in results.items():\n",
    "        #if v == 0 or v == None: continue\n",
    "        if not \"word\" in r: continue\n",
    "        #if not r[:2] in [\"p_\",\"r_\"]: continue\n",
    "        print r,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_asr_RNN', 'test_RNN']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System (eval. method)</th>\n",
       "      <th>$F_{rps}$ (per word)</th>\n",
       "      <th>$F_{rps}$ (per 10s window)</th>\n",
       "      <th>$F_{e}$ (per word)</th>\n",
       "      <th>$F_{e}$ (per 10s window)</th>\n",
       "      <th>$F_{TTO}$ (per word)</th>\n",
       "      <th>$F_{TTO}$ (per 10s window)</th>\n",
       "      <th>DSER (word)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNN (transcript)</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.710</td>\n",
       "      <td>58.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RNN (ASR results)</td>\n",
       "      <td>-</td>\n",
       "      <td>0.542</td>\n",
       "      <td>-</td>\n",
       "      <td>0.718</td>\n",
       "      <td>-</td>\n",
       "      <td>0.681</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  System (eval. method) $F_{rps}$ (per word) $F_{rps}$ (per 10s window)  \\\n",
       "0      RNN (transcript)                0.683                      0.730   \n",
       "1     RNN (ASR results)                    -                      0.542   \n",
       "\n",
       "  $F_{e}$ (per word) $F_{e}$ (per 10s window) $F_{TTO}$ (per word)  \\\n",
       "0              0.909                    0.886                0.704   \n",
       "1                  -                    0.718                    -   \n",
       "\n",
       "  $F_{TTO}$ (per 10s window) DSER (word)  \n",
       "0                      0.710       58.09  \n",
       "1                      0.681           -  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter out the heldout files\n",
    "test_only = [x for x in all_results.keys() if not \"heldout\" in x and not \"complex\" in x]\n",
    "print test_only\n",
    "test_results = {k : all_results[k] for k in test_only}\n",
    "#have a look at the test results\n",
    "final = convert_to_latex(test_results)\n",
    "final = final.drop(final.columns[[-2]], axis=1)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System (eval. method)</th>\n",
       "      <th>TTD$_{rps}$ (word)</th>\n",
       "      <th>TTD$_{rps}$ (time in s)</th>\n",
       "      <th>TTD$_{tto}$ (word)</th>\n",
       "      <th>TTD$_{tto}$ (time in s)</th>\n",
       "      <th>EO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNN (transcript)</td>\n",
       "      <td>1.007</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.350</td>\n",
       "      <td>1.814</td>\n",
       "      <td>11.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RNN (ASR results)</td>\n",
       "      <td>-</td>\n",
       "      <td>0.198</td>\n",
       "      <td>-</td>\n",
       "      <td>3.649</td>\n",
       "      <td>20.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  System (eval. method) TTD$_{rps}$ (word) TTD$_{rps}$ (time in s)  \\\n",
       "0      RNN (transcript)              1.007                   0.253   \n",
       "1     RNN (ASR results)                  -                   0.198   \n",
       "\n",
       "  TTD$_{tto}$ (word) TTD$_{tto}$ (time in s)     EO  \n",
       "0              0.350                   1.814  11.03  \n",
       "1                  -                   3.649  20.53  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc = convert_to_latex(test_results, inc=True)\n",
    "inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write the final and incremental output to a file\n",
    "latex_file = open(\"latex_output_single_tasks_simple.txt\",\"w\")\n",
    "latex_file.write(inc.to_latex(index=False))\n",
    "latex_file.write(\"\\n\\n\" + final.to_latex(index=False))\n",
    "latex_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_asr_RNN <type 'bool'>\n",
      "test_RNN <type 'dict'>\n",
      "heldout_asr_RNN <type 'bool'>\n",
      "heldout_RNN <type 'dict'>\n",
      "heldout_RNN t>\n",
      "\n",
      "FP 834\n",
      "left context=\n",
      "right context=well|<e/><tt> i|<f/><tc> have|<f/><cc> to|<f/><cc> say|<f/><cc>\n",
      "gold left context=\n",
      "gold right context=well|<e/><tc> i|<f/><cc> have|<f/><cc> to|<f/><cc> say|<f/><cc>\n",
      "type = None\n",
      "\n",
      "TP 3264\n",
      "left context=\n",
      "right context=turn|<f/><ct> well|<e/><tt> i|<f/><tc> have|<f/><cc> to|<f/><cc>\n",
      "gold left context=\n",
      "gold right context=turn|<f/><ct> well|<e/><tc> i|<f/><cc> have|<f/><cc> to|<f/><cc>\n",
      "type = None\n",
      "\n",
      "FN 2468\n",
      "left context=i|<f/><cc> really|<f/><cc> dont|<f/><cc> have|<f/><cc> a|<f/><cc>\n",
      "right context=budget|<f/><cc> both|<f/><cc> my|<f/><cc> wife|<f/><cc> and|<f/><cc>\n",
      "gold left context=i|<f/><cc> really|<f/><cc> dont|<f/><cc> have|<f/><cc> a|<f/><cc>\n",
      "gold right context=budget|<f/><ct> both|<f/><tc> my|<f/><cc> wife|<f/><cc> and|<f/><cc>\n",
      "type = None\n",
      "heldout_RNN <rps\n",
      "heldout_RNN <e\n",
      "defaultdict(<type 'int'>, {})\n",
      "defaultdict(<type 'int'>, {})\n",
      "CC & 932 & 16.26\n",
      "subj & 400 & 6.98\n",
      "<e & 279 & 4.87\n",
      "<rps & 165 & 2.88\n",
      " & 71 & 1.24\n",
      "proper_other & 66 & 1.15\n",
      "it & 64 & 1.12\n",
      "ack & 60 & 1.05\n",
      "thats & 20 & 0.35\n",
      "if & 18 & 0.31\n",
      "what & 17 & 0.30\n",
      "my & 17 & 0.30\n",
      "theres & 13 & 0.23\n",
      "when & 12 & 0.21\n",
      "a & 11 & 0.19\n",
      "how & 10 & 0.17\n",
      "do & 10 & 0.17\n",
      "there & 9 & 0.16\n",
      "this & 9 & 0.16\n",
      "is & 9 & 0.16\n",
      "maybe & 9 & 0.16\n",
      "in & 8 & 0.14\n",
      "at & 8 & 0.14\n",
      "theyre & 7 & 0.12\n",
      "th- & 7 & 0.12\n",
      "to & 6 & 0.10\n",
      "then & 6 & 0.10\n",
      "of & 6 & 0.10\n",
      "people & 5 & 0.09\n",
      "probably & 5 & 0.09\n",
      "lets & 4 & 0.07\n",
      "every & 4 & 0.07\n",
      "not & 4 & 0.07\n",
      "like & 4 & 0.07\n",
      "for & 4 & 0.07\n",
      "hes & 4 & 0.07\n",
      "have & 4 & 0.07\n",
      "as & 4 & 0.07\n",
      "go & 3 & 0.05\n",
      "just & 3 & 0.05\n",
      "actually & 3 & 0.05\n",
      "pretty & 3 & 0.05\n",
      "now & 3 & 0.05\n",
      "where & 3 & 0.05\n",
      "an- & 3 & 0.05\n",
      "on & 3 & 0.05\n",
      "whats & 3 & 0.05\n",
      "were & 3 & 0.05\n",
      "youre & 3 & 0.05\n",
      "a- & 3 & 0.05\n",
      "all & 2 & 0.03\n",
      "particularly & 2 & 0.03\n",
      "both & 2 & 0.03\n",
      "somebody & 2 & 0.03\n",
      "possibly & 2 & 0.03\n",
      "weve & 2 & 0.03\n",
      "are & 2 & 0.03\n",
      "our & 2 & 0.03\n",
      "really & 2 & 0.03\n",
      "even & 2 & 0.03\n",
      "who & 2 & 0.03\n",
      "about & 2 & 0.03\n",
      "was & 2 & 0.03\n",
      "sort & 2 & 0.03\n",
      "those & 2 & 0.03\n",
      "theyve & 2 & 0.03\n",
      "up & 2 & 0.03\n",
      "didnt & 2 & 0.03\n",
      "things & 2 & 0.03\n",
      "sure & 2 & 0.03\n",
      "o- & 2 & 0.03\n",
      "most & 2 & 0.03\n",
      "i- & 2 & 0.03\n",
      "why & 2 & 0.03\n",
      "yo- & 2 & 0.03\n",
      "pardon & 1 & 0.02\n",
      "unemployment & 1 & 0.02\n",
      "being & 1 & 0.02\n",
      "wed & 1 & 0.02\n",
      "had & 1 & 0.02\n",
      "late & 1 & 0.02\n",
      "good & 1 & 0.02\n",
      "big & 1 & 0.02\n",
      "television & 1 & 0.02\n",
      "ones & 1 & 0.02\n",
      "course & 1 & 0.02\n",
      "schools & 1 & 0.02\n",
      "taxes & 1 & 0.02\n",
      "did & 1 & 0.02\n",
      "bad & 1 & 0.02\n",
      "either & 1 & 0.02\n",
      "went & 1 & 0.02\n",
      "someday & 1 & 0.02\n",
      "w- & 1 & 0.02\n",
      "theyd & 1 & 0.02\n",
      "some & 1 & 0.02\n",
      "back & 1 & 0.02\n",
      "belie- & 1 & 0.02\n",
      "heres & 1 & 0.02\n",
      "ac- & 1 & 0.02\n",
      "looking & 1 & 0.02\n",
      "goes & 1 & 0.02\n",
      "be & 1 & 0.02\n",
      "never & 1 & 0.02\n",
      "here & 1 & 0.02\n",
      "let & 1 & 0.02\n",
      "plea & 1 & 0.02\n",
      "put & 1 & 0.02\n",
      "by & 1 & 0.02\n",
      "service & 1 & 0.02\n",
      "teachers & 1 & 0.02\n",
      "ill & 1 & 0.02\n",
      "pe- & 1 & 0.02\n",
      "arent & 1 & 0.02\n",
      "youve & 1 & 0.02\n",
      "p- & 1 & 0.02\n",
      "doesnt & 1 & 0.02\n",
      "another & 1 & 0.02\n",
      "bu- & 1 & 0.02\n",
      "drove & 1 & 0.02\n",
      "tha- & 1 & 0.02\n",
      "everybody & 1 & 0.02\n",
      "from & 1 & 0.02\n",
      "would & 1 & 0.02\n",
      "hey & 1 & 0.02\n",
      "their & 1 & 0.02\n",
      "coarse & 1 & 0.02\n",
      "tell & 1 & 0.02\n",
      "selling & 1 & 0.02\n",
      "boy & 1 & 0.02\n",
      "fire & 1 & 0.02\n",
      "nobody & 1 & 0.02\n",
      "huh & 1 & 0.02\n",
      "ended & 1 & 0.02\n",
      "with & 1 & 0.02\n",
      "woman & 1 & 0.02\n",
      "kind & 1 & 0.02\n",
      "unfortunately & 1 & 0.02\n",
      "shes & 1 & 0.02\n",
      "while & 1 & 0.02\n",
      "supposed & 1 & 0.02\n",
      "called & 1 & 0.02\n",
      "tonight & 1 & 0.02\n",
      "say & 1 & 0.02\n",
      "his & 1 & 0.02\n",
      "something & 1 & 0.02\n",
      "apparently & 1 & 0.02\n",
      "any & 1 & 0.02\n",
      "again & 1 & 0.02\n",
      "theyll & 1 & 0.02\n",
      "same & 1 & 0.02\n",
      "other & 1 & 0.02\n",
      "which & 1 & 0.02\n",
      "higher & 1 & 0.02\n",
      "gas & 1 & 0.02\n",
      "after & 1 & 0.02\n",
      "nothing & 1 & 0.02\n",
      "give & 1 & 0.02\n",
      "especially & 1 & 0.02\n",
      "sometimes & 1 & 0.02\n",
      "well & 1 & 0.02\n",
      "definitely & 1 & 0.02\n",
      "putting & 1 & 0.02\n",
      "usu- & 1 & 0.02\n",
      "first & 1 & 0.02\n",
      "once & 1 & 0.02\n",
      "total & 2468 & 43.06\n"
     ]
    }
   ],
   "source": [
    "#Error analyses\n",
    "error = {\"TP\" : {}, \"FP\" : {}, \"FN\": {} }\n",
    " \n",
    "for div,all_error in all_error_dicts.items():\n",
    "    print div, type(all_error)\n",
    "    if type(all_error) == bool: continue\n",
    "    if \"test\" in div: continue\n",
    "    #if not 'TTO only' in div or \"asr\" in div: continue\n",
    "    for tag,errors in all_error.items():\n",
    "        print div, tag\n",
    "        #if not 'TTO only' in div or \"asr\" in div: continue\n",
    "        if not tag == \"t>\": continue\n",
    "        for k,v in errors.items():\n",
    "    \n",
    "            print \"\"\n",
    "            #if k == \"FP\": continue\n",
    "            print k, len(v)\n",
    "            typedict = defaultdict(int)\n",
    "            lendict = defaultdict(int)\n",
    "            print v[0]\n",
    "            for repair in v:\n",
    "                #if len(repair)==0: continue\n",
    "                #print \"*\"\n",
    "                #print repair\n",
    "                #print repair.gold_context\n",
    "                onset = \"\"\n",
    "                if tag == \"<rps\":\n",
    "                    \n",
    "                    for i in rcange(0,len(repair.gold_context)):\n",
    "                        if repair.gold_context[i] == \"+|+\":\n",
    "                            onset = repair.gold_context[i+1]\n",
    "                            break\n",
    "                else:\n",
    "                    gold_onset = \"\"\n",
    "                    onset = \"\"\n",
    "                    word = \"\"\n",
    "                    if len(repair.gold_tags_right_context)>1:\n",
    "                        gold_onset = repair.gold_tags_right_context[1]\n",
    "                        onset = repair.tags_right_context[1]\n",
    "                        word = repair.words_right_context[1]\n",
    "                    #penult = repair.tags_left_context[-1]\n",
    "                    #print repair\n",
    "                    if k == \"FP\":\n",
    "                        onset = gold_onset\n",
    "                    if \"<rps\" in onset:\n",
    "                        typedict[\"<rps\"]+=1\n",
    "                    elif \"<e\" in onset:\n",
    "                        typedict[\"<e\"]+=1\n",
    "                    else:\n",
    "                        if word in [\"and\",\"or\",\"but\",\"so\",\"because\",\"that\",\"although\"]:\n",
    "                            typedict[\"CC\"]+=1\n",
    "                        elif word in [\"i\",\"we\",\"they\",\"im\",\"ive\",\"he\",\"she\",\"id\"]:\n",
    "                            typedict[\"subj\"]+=1\n",
    "                        elif word in [\"you\",\"the\"] or \"$\" in word:\n",
    "                            typedict[\"proper_other\"]+=1\n",
    "                        elif word in [\"yeah\",\"no\",\"okay\",\"yes\",\"right\",\"uh-huh\"]:\n",
    "                            typedict[\"ack\"]+=1\n",
    "                        elif word in [\"it\",\"its\"]:\n",
    "                            typedict[\"it\"]+=1\n",
    "                        else:\n",
    "                            typedict[word]+=1\n",
    "                         \n",
    "                \n",
    "                #if \"<t\" in repair.gold_context\n",
    "                #for t in [\"tt\",\"cc\",\"ct\",\"tc\"]:\n",
    "                #    if \"<\" + t + \">\" in onset:\n",
    "                #        typedict[t]+=1\n",
    "                #        if not t[0]=='t':\n",
    "                #            print repair\n",
    "                if tag == \"<rps\" and not k == 'FP':\n",
    "                    lendict[repair.type]+=1\n",
    "                error[k]['len'] = deepcopy(lendict)\n",
    "                error[k]['type'] = deepcopy(typedict)\n",
    "\n",
    "#tp = deepcopy(lendict)\n",
    "#q1. THE RECALL RATES FOR VARIOUS GOLD REPAIRS\n",
    "tp = error['TP']['len']\n",
    "print tp\n",
    "print error['FN']['len']\n",
    "for k,v in sorted(error['FN']['len'].items()):\n",
    "    print \" & \".join([k, \"({0})\".format(v + tp[k]), \n",
    "                      '{0:.1f}'.format(100 * float(tp[k])/float(v+ tp[k]))]) + \"\\\\\\\\\"\n",
    "\n",
    "tps = error['TP']['type']\n",
    "fns = error['FN']['type']\n",
    "fps = error['FP']['type']\n",
    "\n",
    "total = sum(fns.values()+tps.values())\n",
    "\n",
    "errormass = 0\n",
    "errortotal = 0\n",
    "for k,v in sorted(fns.items(),key= lambda x: x[1],reverse=True):\n",
    "    print k,\"&\",v,\"&\",'{0:.2f}'.format(v/total * 100)\n",
    "    errormass +=(v/total * 100)\n",
    "    errortotal+=v\n",
    "print \"total &\",errortotal,\"&\",'{0:.2f}'.format(errormass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " #TODO for paper/future\n",
    "# - check WER for ASR results and exclude those with high ones given they might have high overlap :(\n",
    "# - need to adjust the time to detection scores based on the time it comes in from Increco?? \n",
    "#      Also for ttdetection can only use word ends unless we re-do the mapping- just needs explanation\n",
    "# - delayed accuracy based on time, or not bother? do moving window instead and plot this over time- average moving window accuracy\n",
    "# - error analysis plots\n",
    "# 036- full task with LSTM- should improve massively over 034, which also needs re-running\n",
    "# Reproduce 027 (with full training data, efficiently) and re-run with LSTM- not much time.\n",
    "#Q2 TODO the extent to which the network is memorizing- need to plug these in with the repair gold standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
