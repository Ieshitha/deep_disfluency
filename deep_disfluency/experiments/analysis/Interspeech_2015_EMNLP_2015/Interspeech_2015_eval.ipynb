{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "# add the deep_disfluency module to the path\n",
    "sys.path.append(\"../../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from deep_disfluency.evaluation.disf_evaluation import incremental_output_disfluency_eval_from_file\n",
    "from deep_disfluency.evaluation.disf_evaluation import final_output_disfluency_eval_from_file\n",
    "from deep_disfluency.evaluation.eval_utils import get_tag_data_from_corpus_file\n",
    "from deep_disfluency.evaluation.eval_utils import rename_all_repairs_in_line_with_index\n",
    "from deep_disfluency.evaluation.eval_utils import sort_into_dialogue_speakers\n",
    "from deep_disfluency.evaluation.results_utils import convert_to_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the locations of all needed files\n",
    "# Assume we have the incremental output\n",
    "experiment_dir = \"../../../experiments\"\n",
    "\n",
    "partial_words = False  # No partial words in these experiments, removed\n",
    "if partial_words:\n",
    "    partial = '_partial'\n",
    "else:\n",
    "    partial = ''\n",
    "#the evaluation files (as text files)\n",
    "disf_dir = \"../../../data/disfluency_detection/switchboard\"\n",
    "disfluency_files = [\n",
    "                    disf_dir + \"/swbd_disf_heldout{}_data_timings.csv\".format(partial),\n",
    "                    disf_dir + \"/swbd_disf_test{}_data_timings.csv\".format(partial)\n",
    "                   ]\n",
    "    \n",
    "\n",
    "allsystemsfinal = [\"021/epoch_40\",\n",
    "                   \"041/epoch_16\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "021/epoch_40\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julian/.local/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing final output to file ../../../experiments/021/epoch_40/swbd_disf_heldout_data_output_final.text\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "writing final output to file ../../../experiments/021/epoch_40/swbd_disf_test_data_output_final.text\n",
      "041/epoch_16\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "writing final output to file ../../../experiments/041/epoch_16/swbd_disf_heldout_data_output_final.text\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "incremental output disfluency evaluation\n",
      "word= True interval= False utt_eval= True\n",
      "writing final output to file ../../../experiments/041/epoch_16/swbd_disf_test_data_output_final.text\n"
     ]
    }
   ],
   "source": [
    "# create final output files for the final output evaluation (and do incremental evaluation first:\n",
    "DO_INCREMENTAL_EVAL = True\n",
    "VERBOSE = False\n",
    "if DO_INCREMENTAL_EVAL:\n",
    "    all_incremental_results = {}\n",
    "    all_incremental_error_dicts = {}\n",
    "    for system in allsystemsfinal:\n",
    "        print system\n",
    "        #if 'complex' in system: break\n",
    "        hyp_dir = experiment_dir + \"/\" + system\n",
    "        #hyp_dir = experiment_dir\n",
    "        for division, disf_file in zip([\"heldout\",\"test\"], disfluency_files):\n",
    "            print \"*\" * 30, division, \"*\" * 30\n",
    "            IDs, timings, words, pos_tags, labels = get_tag_data_from_corpus_file(disf_file)\n",
    "            gold_data = {} #map from the file name to the data\n",
    "            for dialogue,a,b,c,d in zip(IDs, timings, words, pos_tags, labels):\n",
    "                # if \"asr\" in division and not dialogue[:4] in good_asr: continue\n",
    "                gold_data[dialogue] = (a,b,c,d)\n",
    "            inc_filename = hyp_dir + \"/swbd_disf_{0}{1}_data_output_increco\".format(division, partial) + \".text\"\n",
    "            final_output_name = inc_filename.replace(\"_increco\", \"_final\")\n",
    "            results, error_analysis = incremental_output_disfluency_eval_from_file(\n",
    "                                                                             inc_filename,\n",
    "                                                                             gold_data,\n",
    "                                                                             utt_eval=True,\n",
    "                                                                             error_analysis=True,\n",
    "                                                                             word=True,\n",
    "                                                                             interval=False,\n",
    "                                                                             outputfilename=final_output_name)\n",
    "            if VERBOSE:\n",
    "                for k,v in results.items():\n",
    "                    print k,v\n",
    "            all_incremental_results[division + \"_\" + system] = deepcopy(results)\n",
    "            if \"heldout\" in division:\n",
    "                # only do the error analyses on the heldout data\n",
    "                all_incremental_error_dicts[division + \"_\" + system] = deepcopy(error_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System (eval. method)</th>\n",
       "      <th>TTD$_{rms}$ (word)</th>\n",
       "      <th>TTD$_{rps}$ (word)</th>\n",
       "      <th>EO (word)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM (window length=2) (+ POS) (transcript)</td>\n",
       "      <td>2.369</td>\n",
       "      <td>1.083</td>\n",
       "      <td>3.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RNN (window length=2) (+ POS) (transcript)</td>\n",
       "      <td>2.413</td>\n",
       "      <td>1.087</td>\n",
       "      <td>3.259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         System (eval. method) TTD$_{rms}$ (word)  \\\n",
       "0  LSTM (window length=2) (+ POS) (transcript)              2.369   \n",
       "1   RNN (window length=2) (+ POS) (transcript)              2.413   \n",
       "\n",
       "  TTD$_{rps}$ (word) EO (word)  \n",
       "0              1.083     3.136  \n",
       "1              1.087     3.259  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = \"No incremental results here\"\n",
    "if DO_INCREMENTAL_EVAL:\n",
    "    display_results = dict()\n",
    "    display_results['RNN (window length=2) (+ POS)'] = all_incremental_results['test_021/epoch_40']\n",
    "    display_results['LSTM (window length=2) (+ POS)'] = all_incremental_results['test_041/epoch_16']\n",
    "    final = convert_to_latex(display_results, eval_level=['word'], inc=True, utt_seg=False, only_include=\n",
    "                            ['t_t_detection_<rms_word', 't_t_detection_<rps_word', 'edit_overhead_rel_word'])\n",
    "    #final = final.drop(final.columns[[-2]], axis=1)\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final output evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "021/epoch_40\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= False\n",
      "word\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= False\n",
      "word\n",
      "041/epoch_16\n",
      "****************************** heldout ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_heldout_data_timings.csv\n",
      "loaded 102 sequences\n",
      "102 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= False\n",
      "word\n",
      "****************************** test ******************************\n",
      "loading data ../../../data/disfluency_detection/switchboard/swbd_disf_test_data_timings.csv\n",
      "loaded 100 sequences\n",
      "100 speakers\n",
      "final output disfluency evaluation\n",
      "word= True interval= False utt_eval= False\n",
      "word\n"
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "all_error_dicts = {}\n",
    "VERBOSE = False\n",
    "for system in allsystemsfinal:\n",
    "    print system\n",
    "    #if 'complex' in system: break\n",
    "    hyp_dir = experiment_dir\n",
    "    for division, disf_file in zip([\"heldout\", \"test\"],disfluency_files):\n",
    "        #if not division == \"heldout\": continue\n",
    "        print \"*\" * 30, division, \"*\" * 30\n",
    "        IDs, timings, words, pos_tags, labels = get_tag_data_from_corpus_file(disf_file)\n",
    "        gold_data = {} #map from the file name to the data\n",
    "        for dialogue,a,b,c,d in zip(IDs, timings, words, pos_tags, labels):\n",
    "            # if \"asr\" in division and not dialogue[:4] in good_asr: continue\n",
    "            d = rename_all_repairs_in_line_with_index(list(d))\n",
    "            gold_data[dialogue] = (a,b,c,d)\n",
    "\n",
    "        #the below does just the final output evaluation, assuming a final output file, faster\n",
    "        hyp_file = hyp_dir + '/' + system + \"/\" + \"swbd_disf_{0}{1}_data_output_final.text\".format(division,\n",
    "                                                                                                        partial)\n",
    "        word = True  # world-level analyses\n",
    "        error = True # get an error analysis\n",
    "        results,speaker_rate_dict,error_analysis = final_output_disfluency_eval_from_file(\n",
    "                                                        hyp_file,\n",
    "                                                        gold_data,\n",
    "                                                        utt_eval=False,\n",
    "                                                        error_analysis=error,\n",
    "                                                        word=word,\n",
    "                                                        interval=False,\n",
    "                                                        outputfilename=None\n",
    "                                                    )\n",
    "        #the below does incremental and final output in one, also outputting the final outputs\n",
    "        #derivable from the incremental output, takes quite a while\n",
    "        if VERBOSE:\n",
    "            for k,v in results.items():\n",
    "                print k,v\n",
    "        all_results[division + \"_\" + system] = deepcopy(results)\n",
    "        if \"heldout\" in division:\n",
    "            # only do the error analyses on the heldout data\n",
    "            all_error_dicts[division + \"_\" + system] = deepcopy(error_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['heldout_041/epoch_16', 'heldout_021/epoch_40', 'test_021/epoch_40', 'test_041/epoch_16']\n"
     ]
    }
   ],
   "source": [
    "print all_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System (eval. method)</th>\n",
       "      <th>$F_{rm}$ (per word)</th>\n",
       "      <th>$F_{rps}$ (per word)</th>\n",
       "      <th>$F_{e}$ (per word)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM (window length=2) (+ POS) (transcript)</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RNN (window length=2) (+ POS) (transcript)</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         System (eval. method) $F_{rm}$ (per word)  \\\n",
       "0  LSTM (window length=2) (+ POS) (transcript)               0.620   \n",
       "1   RNN (window length=2) (+ POS) (transcript)               0.627   \n",
       "\n",
       "  $F_{rps}$ (per word) $F_{e}$ (per word)  \n",
       "0                0.721              0.887  \n",
       "1                0.721              0.856  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_results = dict()\n",
    "display_results['RNN (window length=2) (+ POS)'] = all_results['test_021/epoch_40']\n",
    "display_results['LSTM (window length=2) (+ POS)'] = all_results['test_041/epoch_16']\n",
    "final = convert_to_latex(display_results, eval_level=['word'], inc=False, utt_seg=False, only_include=\n",
    "                        ['f1_<rm_word', 'f1_<rps_word', 'f1_<e_word'])\n",
    "#final = final.drop(final.columns[[-2]], axis=1)\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************** heldout_041/epoch_16 <rps ******************************\n",
      "type ******************************\n",
      "del & (17/101) & 0.286\\\\\n",
      "rep & (821/1001) & 0.894\\\\\n",
      "sub & (368/844) & 0.573\\\\\n",
      "0.6197327852\n",
      "len ******************************\n",
      "0 & (0/1) & 0.000\\\\\n",
      "1 & (850/1096) & 0.856\\\\\n",
      "2 & (246/467) & 0.659\\\\\n",
      "3 & (68/205) & 0.482\\\\\n",
      "4 & (25/88) & 0.424\\\\\n",
      "5 & (8/46) & 0.296\\\\\n",
      "6 & (7/26) & 0.424\\\\\n",
      "7 & (0/8) & 0.000\\\\\n",
      "8 & (2/5) & 0.571\\\\\n",
      "9 & (0/1) & 0.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/1) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.6197327852\n",
      "****************************** heldout_041/epoch_16 <rms ******************************\n",
      "type ******************************\n",
      "del & (1/93) & 0.021\\\\\n",
      "rep & (868/1069) & 0.871\\\\\n",
      "sub & (235/784) & 0.411\\\\\n",
      "0.567317574512\n",
      "len ******************************\n",
      "1 & (828/1095) & 0.827\\\\\n",
      "2 & (218/469) & 0.580\\\\\n",
      "3 & (44/207) & 0.319\\\\\n",
      "4 & (12/86) & 0.222\\\\\n",
      "5 & (2/46) & 0.078\\\\\n",
      "6 & (0/26) & 0.000\\\\\n",
      "7 & (0/8) & 0.000\\\\\n",
      "8 & (0/5) & 0.000\\\\\n",
      "9 & (0/1) & 0.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/1) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.567317574512\n",
      "****************************** heldout_021/epoch_40 <rps ******************************\n",
      "type ******************************\n",
      "del & (18/101) & 0.303\\\\\n",
      "rep & (824/1001) & 0.898\\\\\n",
      "sub & (399/844) & 0.611\\\\\n",
      "0.637718396711\n",
      "len ******************************\n",
      "0 & (0/1) & 0.000\\\\\n",
      "1 & (845/1096) & 0.859\\\\\n",
      "2 & (278/467) & 0.728\\\\\n",
      "3 & (72/205) & 0.491\\\\\n",
      "4 & (30/88) & 0.462\\\\\n",
      "5 & (7/46) & 0.264\\\\\n",
      "6 & (6/26) & 0.375\\\\\n",
      "7 & (1/8) & 0.222\\\\\n",
      "8 & (1/5) & 0.333\\\\\n",
      "9 & (1/1) & 1.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/1) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.637718396711\n",
      "****************************** heldout_021/epoch_40 <rms ******************************\n",
      "type ******************************\n",
      "del & (0/86) & 0.000\\\\\n",
      "rep & (863/1067) & 0.873\\\\\n",
      "sub & (294/793) & 0.495\\\\\n",
      "0.594552929085\n",
      "len ******************************\n",
      "1 & (820/1093) & 0.835\\\\\n",
      "2 & (258/470) & 0.664\\\\\n",
      "3 & (57/206) & 0.390\\\\\n",
      "4 & (21/89) & 0.326\\\\\n",
      "5 & (1/46) & 0.042\\\\\n",
      "6 & (0/25) & 0.000\\\\\n",
      "7 & (0/8) & 0.000\\\\\n",
      "8 & (0/5) & 0.000\\\\\n",
      "9 & (0/1) & 0.000\\\\\n",
      "10 & (0/1) & 0.000\\\\\n",
      "11 & (0/1) & 0.000\\\\\n",
      "15 & (0/1) & 0.000\\\\\n",
      "0.594552929085\n"
     ]
    }
   ],
   "source": [
    "#Error analyses on exact match ('rms') and getting the right repair start ('rps')\n",
    "target_tags = ['<rms', '<rps']\n",
    "\n",
    "for div,all_error in all_error_dicts.items():\n",
    "    # print div, type(all_error)\n",
    "   \n",
    "    if type(all_error) == bool: continue\n",
    "    if \"test\" in div: continue\n",
    "    #if not 'TTO only' in div or \"asr\" in div: continue\n",
    "    for tag, errors in all_error.items():\n",
    "        if tag not in target_tags:\n",
    "            continue\n",
    "        print \"*\" * 30, div, tag, \"*\" * 30\n",
    "        # print errors\n",
    "        # continue\n",
    "        #if not 'TTO only' in div or \"asr\" in div: continue\n",
    "        error = {\"TP\" : {}, \"FP\" : {}, \"FN\": {} }\n",
    "        for k,v in errors.items():\n",
    "            #if k == \"FP\":\n",
    "            #    continue\n",
    "            # print k, len(v)\n",
    "            typedict = defaultdict(int)\n",
    "            lendict = defaultdict(int)\n",
    "            for repair in v:\n",
    "\n",
    "                #print repair.gold_context\n",
    "                onset = \"\"\n",
    "                if tag == \"<rps\" or tag == \"<rms\":\n",
    "                    \n",
    "                    \n",
    "                    for i in range(0,len(repair.gold_context)):\n",
    "                        if repair.gold_context[i] == \"+|+\":\n",
    "                            onset = repair.gold_context[i+1]\n",
    "                            break\n",
    "\n",
    "                    word = onset.split(\"|\")[0]\n",
    "                    #if k == \"FP\":\n",
    "                    #    onset = gold_onset\n",
    "                    if \"<e\" in onset and not tag == \"<e\":\n",
    "                        typedict[\"<e\"]+=1\n",
    "                    else:\n",
    "                        if word in [\"and\",\"or\",\"but\",\"so\",\"because\",\"that\",\"although\"]:\n",
    "                            typedict[\"CC\"]+=1\n",
    "                        elif word in [\"i\",\"we\",\"they\",\"im\",\"ive\",\"he\",\"she\",\"id\"]:\n",
    "                            typedict[\"subj\"]+=1\n",
    "                        elif word in [\"you\",\"the\"] or \"$\" in word:\n",
    "                            typedict[\"proper_other\"]+=1\n",
    "                        elif word in [\"yeah\",\"no\",\"okay\",\"yes\",\"right\",\"uh-huh\"]:\n",
    "                            typedict[\"ack\"]+=1\n",
    "                        elif word in [\"it\",\"its\"]:\n",
    "                            typedict[\"it\"]+=1\n",
    "                        else:\n",
    "                            typedict[word]+=1\n",
    "                \n",
    "                if tag == \"<rps\" or tag == \"<rms\": # and not k == 'FP':\n",
    "                    if k == \"TP\" and len(repair.reparandumWords) > 8:\n",
    "                        # should not be getting any over 8 words\n",
    "                        print \"** overlength repair!\"\n",
    "                        print repair\n",
    "                    lendict[len(repair.reparandumWords) + len(repair.interregnumWords)]+=1\n",
    "                    repair_type = None\n",
    "                    if repair.type:\n",
    "                        repair_type = repair.type \n",
    "                        typedict[repair_type]+=1\n",
    "\n",
    "            error[k]['len'] = deepcopy(lendict)\n",
    "            error[k]['type'] = deepcopy(typedict)\n",
    "\n",
    "                \n",
    "        for mode in ['type', 'len']:\n",
    "            #q1. THE RECALL RATES FOR VARIOUS GOLD REPAIR TYPES\n",
    "            print mode, \"*\" * 30\n",
    "            tps = error['TP'][mode]\n",
    "            fns = error['FN'][mode]\n",
    "            fps = error['FP'][mode]\n",
    "\n",
    "            total_tps = 0\n",
    "            total_fns = 0\n",
    "            total_fps = 0\n",
    "            top_n = 50\n",
    "            all_items = list(set(tps.keys() + fns.keys()))\n",
    "            # print all_items\n",
    "            for k in sorted(all_items,  reverse=False):\n",
    "                #print k, \"*\" * 30\n",
    "                if mode == 'type' and k not in [\"rep\", \"del\", \"sub\"]:\n",
    "                    continue\n",
    "                recall_total = tps[k] + fns[k]\n",
    "                recall = 0 if tps[k] == 0 else tps[k]/recall_total\n",
    "                precision_total = tps[k] + fps[k]\n",
    "                precision = 0 if tps[k] == 0 else tps[k]/precision_total\n",
    "                fscore = 0 if precision == 0 or recall == 0 else (2 * (precision * recall))/(precision + recall)\n",
    "                # print k, ':', tps[k], \"out of\", recall_total\n",
    "                #print k, ':', tps[k], \"out of\", precision_total\n",
    "                total_tps += tps[k]\n",
    "                total_fns += fns[k]\n",
    "                total_fps += fps[k]\n",
    "                print \" & \".join([str(k), \"({0}/{1})\".format(tps[k],recall_total), \n",
    "                                  '{0:.3f}'.format(fscore)]) + \"\\\\\\\\\"\n",
    "                top_n-=1\n",
    "                if top_n <= 0:\n",
    "                    break\n",
    "            print total_tps/(total_fns + total_tps)\n",
    "\n",
    "            if False:\n",
    "                #q2. ERROR TYPE SUMMARY\n",
    "                print \"*\" * 30\n",
    "                total = sum(fns.values()+tps.values())\n",
    "\n",
    "                errormass = 0\n",
    "                errortotal = 0\n",
    "                top_n = 20\n",
    "                for k,v in sorted(tps.items(),key= lambda x: x[1],reverse=True):\n",
    "                    print k,\"&\",v,\"&\",'{0:.2f}'.format(v/total)\n",
    "                    errormass +=(v/total * 100)\n",
    "                    errortotal+=v\n",
    "                    top_n-=1\n",
    "                    if top_n <= 0: break\n",
    "                print \"total &\",errortotal,\"&\",'{0:.2f}'.format(errormass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
